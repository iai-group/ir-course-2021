# L10: Advanced topics

This last module discusses more advanced topics. First, continuing last week's module on transformer-based approaches, we will present different ways of expanding documents using neural networks and techniques for improving the effectiveness and efficiency of neural methods. Second, we take a closer look at subword-based tokenization, specifically, the WordPiece algorithm. Finally, we look at the emerging theme of conversational AI from an information retrieval perspective and highlight challenges, esp. related to evaluation.

## Lecture videos and slides

| **Module** | **Topic** | **Lecture material** |
| -- | -- | -- | 
| L10-1 | Pretrained transformers for text ranking Part II | [lecture video -- watch from 1:19:54 to 1:48:52](https://youtu.be/_Mmhl0egDmY?t=4794),  **TODO** [slides]() |
| L10-2 | Subword tokenization  | **TODO** [slides]() |
| L10-3 | Conversational AI  | [lecture video -- watch until 22:20](https://www.youtube.com/watch?v=UDwPclwYIh0), **TODO** [slides]() |


## Reading


  * Pretrained Transformers for Text Ranking: BERT and Beyond (Lin, Nogueira & Yates, 2020) [PDF](https://arxiv.org/abs/2010.06467)
  * Conversational AI from an Information Retrieval Perspective: Remaining Challenges and a Case for User Simulation (Balog, 2021) [PDF](https://krisztianbalog.com/files/desires2021-cia.pdf)
  * Word, Subword, and Character-Based Tokenization: Know the Difference [article](https://towardsdatascience.com/word-subword-and-character-based-tokenization-know-the-difference-ea0976b64e17)
  * WordPiece tokenizer (bottom-up approach) [article](https://towardsdatascience.com/wordpiece-subword-based-tokenization-algorithm-1fbd14394ed7)
  * WordPiece tokenizer (top-down approach) [article](https://www.tensorflow.org/text/guide/subwords_tokenizer#optional_the_algorithm)


## Summary

Key concepts in this lecture:

  * **TODO**
